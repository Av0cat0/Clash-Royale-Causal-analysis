{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import projcore as pc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import ast\n",
    "import random\n",
    "import seaborn as sns\n",
    "from gensim.models import Word2Vec\n",
    "import networkx as nx\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File BattlesStaging_01012021_WL_tagged/BattlesStaging_01012021_WL_tagged.csv already exists, skipping download\n",
      "File CardMasterListSeason18_12082020.csv already exists, skipping download\n",
      "File Wincons.csv already exists, skipping download\n",
      "clash-royal-data.csv already exists, skipping download\n"
     ]
    }
   ],
   "source": [
    "pc.download_kaggle_datasets()\n",
    "org_battles_df = pd.read_csv('BattlesStaging_01012021_WL_tagged.csv')\n",
    "card_list_df = pd.read_csv('CardMasterListSeason18_12082020.csv')\n",
    "winning_card_list_df = pd.read_csv('Wincons.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24741492819344177\n"
     ]
    }
   ],
   "source": [
    "#battles_df = pc.feature_preprocessing(org_battles_df, winning_card_list_df)\n",
    "org_battles_df.head(100).to_csv(\"org_battles_subset.csv\", index=False)\n",
    "print(battles_df['winner.high_win_rate'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_decks = battles_df[\"winner.card_set\"].unique()\n",
    "deck_wins = battles_df.groupby(\"winner.card_set\").size()\n",
    "deck_losses = battles_df.groupby(\"loser.card_set\").size()\n",
    "deck_total_games = deck_wins.add(deck_losses, fill_value=0)\n",
    "deck_win_rate = (deck_wins / deck_total_games).fillna(0)  # Win rate as fraction\n",
    "win_rate_dict = deck_win_rate.to_dict()\n",
    "\n",
    "# DIFFERENT TASK?\n",
    "winner_deck_counts = battles_df[\"winner.card_set\"].value_counts()\n",
    "loser_deck_counts = battles_df[\"loser.card_set\"].value_counts()\n",
    "deck_counts = winner_deck_counts.add(loser_deck_counts, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_decks = set(deck_counts[deck_counts >= 25].index)\n",
    "filtered_battles_df = battles_df[battles_df[\"winner.card_set\"].isin(valid_decks)]\n",
    "unique_decks = filtered_battles_df[\"winner.card_set\"].unique()\n",
    "print(\"Number of unique decks:\", len(unique_decks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute win rates for each deck\n",
    "deck_wins = battles_df.groupby(\"winner.card_set\").size()\n",
    "deck_losses = battles_df.groupby(\"loser.card_set\").size()\n",
    "deck_total_games = deck_wins.add(deck_losses, fill_value=0)\n",
    "deck_win_rate = (deck_wins / deck_total_games).fillna(0)  # Win rate as fraction\n",
    "\n",
    "\n",
    "# Store win rates in a dictionary\n",
    "win_rate_dict = deck_win_rate.to_dict()\n",
    "\n",
    "# Construct a Deck Similarity Graph (Graph-based Representation)\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add decks as nodes with win rate as an attribute\n",
    "for deck in unique_decks:\n",
    "    G.add_node(deck, win_rate=win_rate_dict.get(deck, 0))\n",
    "\n",
    "# Define a function to compute deck similarity (overlap of at least 5 cards)\n",
    "def deck_similarity(deck1, deck2, min_overlap=5):\n",
    "    return len(set(deck1) & set(deck2)) >= min_overlap\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "\n",
    "# Add edges between similar decks (reducing full pairwise computation)\n",
    "for i in range(len(unique_decks)):\n",
    "    for j in range(i + 1, len(unique_decks)):\n",
    "        if deck_similarity(unique_decks[i], unique_decks[j]):\n",
    "            G.add_edge(unique_decks[i], unique_decks[j])\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "# Train DeepWalk using Word2Vec on random walks from the graph\n",
    "walks = [list(map(str, nx.single_source_shortest_path_length(G, node, cutoff=10).keys())) for node in G.nodes()]\n",
    "deepwalk_model = Word2Vec(sentences=walks, vector_size=64, window=5, min_count=1, sg=1, workers=4)\n",
    "\n",
    "# Extract embeddings for each deck\n",
    "deck_embeddings = {deck: deepwalk_model.wv[str(deck)] for deck in G.nodes()}\n",
    "print(\"Number of embeddings:\", len(deck_embeddings))\n",
    "# Convert embeddings to a DataFrame for visualization\n",
    "deck_embedding_df = pd.DataFrame(deck_embeddings).T\n",
    "deck_embedding_df[\"WinRate\"] = [G.nodes[deck][\"win_rate\"] for deck in deck_embedding_df.index]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
