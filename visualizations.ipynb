{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management Algorithm for Decision Making in Clash Royale\n",
    "**Analyzing User Behavior in Clash Royale for Strategic Decision Making**\n",
    "\n",
    "## Project Rationale\n",
    "This project aims to leverage advanced data management algorithms to analyze user behavior in the popular mobile game Clash Royale.<br>\n",
    "By utilizing datasets obtained from Kaggle, we will explore how different user behaviors impact game outcomes.<br>\n",
    "The goal is to apply techniques learned in the course to understand which behaviors lead to winning, prolonged gameplay, and frequent app usage.\n",
    "\n",
    "we will focuses on handling various steps in the data-driven decision-making process, including data integration, cleaning, and exploration.<br>\n",
    "In this project we will address common data issues such as missing data, dirty or inconsistent data, and bias, ensuring trustworthy decision-making.\n",
    "\n",
    "## Data Description\n",
    "We will use the following datasets:\n",
    "1. **BattlesStaging_01012021_WL_tagged.csv**: Contains data on games played on January 1, 2021. each row present 1 game between 2 players.\n",
    "2. **Wincons.csv**: Contains information about impactful cards in the game.\n",
    "3. **clash_royal_data.csv**: Contains specific card data, including ratings and usage statistics.\n",
    "\n",
    "### Columns in BattlesStaging_01012021_WL_tagged.csv\n",
    "- `Unnamed: 0`: Index\n",
    "- `battleTime`: The time the battle started\n",
    "- `arena.id`: The ID of the arena where the battle took place\n",
    "- `gameMode.id`: The ID of the game mode\n",
    "- `average.startingTrophies`: The average starting trophies of both players\n",
    "- `winner.tag`: The tag of the winning player\n",
    "- `winner.startingTrophies`: The starting trophies of the winning player\n",
    "- `winner.trophyChange`: The change in trophies for the winning player\n",
    "- `winner.crowns`: The number of crowns earned by the winning player\n",
    "- `winner.kingTowerHitPoints`: The hit points of the winning player's king tower\n",
    "- `winner.princessTowersHitPoints`: The hit points of the winning player's princess towers\n",
    "- `winner.clan.tag`: The clan tag of the winning player\n",
    "- `winner.clan.badgeId`: The clan badge ID of the winning player\n",
    "- `loser.tag`: The tag of the losing player\n",
    "- `loser.startingTrophies`: The starting trophies of the losing player\n",
    "- `loser.trophyChange`: The change in trophies for the losing player\n",
    "- `loser.crowns`: The number of crowns earned by the losing player\n",
    "- `loser.kingTowerHitPoints`: The hit points of the losing player's king tower\n",
    "- `loser.clan.tag`: The clan tag of the losing player\n",
    "- `loser.clan.badgeId`: The clan badge ID of the losing player\n",
    "- `loser.princessTowersHitPoints`: The hit points of the losing player's princess towers\n",
    "- `tournamentTag`: The tag of the tournament (if applicable)\n",
    "- `winner.card1.id` to `winner.card8.id`: The IDs of the winning player's cards\n",
    "- `winner.card1.level` to `winner.card8.level`: The levels of the winning player's cards\n",
    "- `winner.cards.list`: The list of cards of the winning player\n",
    "- `winner.totalcard.level`: The total level of the cards of the winning player\n",
    "- `winner.troop.count`: The count of troop cards of the winning player\n",
    "- `winner.structure.count`: The count of structure cards of the winning player\n",
    "- `winner.spell.count`: The count of spell cards of the winning player\n",
    "- `winner.common.count`: The count of common cards of the winning player\n",
    "- `winner.rare.count`: The count of rare cards of the winning player\n",
    "- `winner.epic.count`: The count of epic cards of the winning player\n",
    "- `winner.legendary.count`: The count of legendary cards of the winning player\n",
    "- `winner.elixir.average`: The average elixir cost of the winning player's deck\n",
    "- `loser.card1.id` to `loser.card8.id`: The IDs of the losing player's cards\n",
    "- `loser.card1.level` to `loser.card8.level`: The levels of the losing player's cards\n",
    "- `loser.cards.list`: The list of cards of the losing player\n",
    "- `loser.totalcard.level`: The total level of the cards of the losing player\n",
    "- `loser.troop.count`: The count of troop cards of the losing player\n",
    "- `loser.structure.count`: The count of structure cards of the losing player\n",
    "- `loser.spell.count`: The count of spell cards of the losing player\n",
    "- `loser.common.count`: The count of common cards of the losing player\n",
    "- `loser.rare.count`: The count of rare cards of the losing player\n",
    "- `loser.epic.count`: The count of epic cards of the losing player\n",
    "- `loser.legendary.count`: The count of legendary cards of the losing player\n",
    "- `loser.elixir.average`: The average elixir cost of the losing player's deck\n",
    "\n",
    "### Columns in Wincons.csv\n",
    "- `id`: Index\n",
    "- `card_id`: The ID of the card\n",
    "- `card_name`: The name of the card\n",
    "\n",
    "### Columns in clash_royal_data.csv\n",
    "- `name`: The name of the card\n",
    "- `Rating`: The rating of the card\n",
    "- `Usage`: The usage percentage of the card\n",
    "- `increase_in_usage`: The increase in usage percentage\n",
    "- `Win`: The win percentage of the card\n",
    "- `increase_in_win`: The increase in win percentage\n",
    "- `CWR`: The card win rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# Import necessary libraries\n",
    "import projcore as pc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Integration, Cleaning, and Exploration\n",
    "We will start by loading the datasets. We will then clean and explore the data to ensure it is ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pc\u001b[38;5;241m.\u001b[39mdownload_kaggle_datasets()\n\u001b[0;32m----> 2\u001b[0m battles_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBattlesStaging_01012021_WL_tagged.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m card_list_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCardMasterListSeason18_12082020.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m winning_card_list_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWincons.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/technion/nihul_lekabalat_ahlatot/the_project/Clash-Royale-Causal-analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/technion/nihul_lekabalat_ahlatot/the_project/Clash-Royale-Causal-analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/technion/nihul_lekabalat_ahlatot/the_project/Clash-Royale-Causal-analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Desktop/technion/nihul_lekabalat_ahlatot/the_project/Clash-Royale-Causal-analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/Desktop/technion/nihul_lekabalat_ahlatot/the_project/Clash-Royale-Causal-analysis/.venv/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:376\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    374\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m union_categoricals(arrs, sort_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     result[name] \u001b[38;5;241m=\u001b[39m \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_cat_dtypes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m result[name]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    378\u001b[0m         warning_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(name))\n",
      "File \u001b[0;32m~/Desktop/technion/nihul_lekabalat_ahlatot/the_project/Clash-Royale-Causal-analysis/.venv/lib/python3.11/site-packages/pandas/core/dtypes/concat.py:78\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     77\u001b[0m     to_concat_arrs \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[np.ndarray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat_arrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pc.download_kaggle_datasets()\n",
    "battles_df = pd.read_csv('BattlesStaging_01012021_WL_tagged.csv')\n",
    "card_list_df = pd.read_csv('CardMasterListSeason18_12082020.csv')\n",
    "winning_card_list_df = pd.read_csv('Wincons.csv')\n",
    "battles_df = pc.feature_preprocessing(battles_df, winning_card_list_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We will create new features to enhance our analysis. This includes calculating the elixir variability, trophy efficiency, and other metrics that can help us understand the factors influencing game outcomes.\n",
    "\n",
    "In the next section, we create new features to enhance our analysis. These features include:\n",
    "\n",
    "- `deck_elixir_variability`: Measures the variability in elixir cost between the winner and loser.\n",
    "- `winner_trophy_eff` and `loser_trophy_eff`: Calculate the trophy efficiency for the winner and loser, respectively.\n",
    "- `winner_card_level_std` and `loser_card_level_std`: Calculate the standard deviation of the levels of the winner's and loser's cards.\n",
    "- `winner_spell_troop_ratio` and `loser_spell_troop_ratio`: Calculate the ratio of spell cards to troop cards for the winner and loser.\n",
    "- `elixir_gap`: Measures the difference in average elixir cost between the winner and loser.\n",
    "- `winner_rarity_diversity` and `loser_rarity_diversity`: Measure the diversity of card rarities in the winner's and loser's decks.\n",
    "- `princess_tower_gap`: Measures the difference in princess tower hit points between the winner and loser.\n",
    "- `win_streak_proxy`: A proxy for the winner's win streak.\n",
    "- `winner_has_legendary` and `loser_has_legendary`: Indicate whether the winner or loser has legendary cards.\n",
    "- `clan_advantage`: Indicates whether the winner has a clan advantage.\n",
    "- `elixir_advantage`: Indicates whether the winner has an elixir advantage.\n",
    "- `balanced_deck_winner` and `balanced_deck_loser`: Indicate whether the winner or loser has a balanced deck.\n",
    "- `underleveled_winner` and `underleveled_loser`: Indicate whether the winner or loser is underleveled for the arena.\n",
    "- `crown_dominance`: Indicates whether the winner has crown dominance.\n",
    "- `winner_count`\n",
    "- `loser_count`\n",
    "- `total_games`\n",
    "- `win_lose_ratio`\n",
    "- `winner_winning_card_count`\n",
    "- `loser_winning_card_count`\n",
    "- `winner_card_set`\n",
    "- `loser_card_set`\n",
    "- `winner_deck_final_score`\n",
    "\n",
    "\n",
    "These features help us understand the factors influencing game outcomes by providing more detailed metrics on player performance, deck composition, and game dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YAGEL OR SALEH: GIVE GOOD NAME LIKE CASUAL INFERENCE OR SOMETHING LIKE THAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to build our DAG, we will start with correlation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix for the specified features\n",
    "battles_df_for_dag = battles_df.copy()\n",
    "battles_df_for_dag['loser_card_set'] = pd.factorize(battles_df_for_dag['loser_card_set'])[0]\n",
    "battles_df_for_dag['winner_card_set'] = pd.factorize(battles_df_for_dag['winner_card_set'])[0]\n",
    "\n",
    "correlation_matrix = battles_df_for_dag.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(correlation_matrix.iloc[1:,1:], annot=False, cmap='coolwarm') # no need for index\n",
    "plt.title('Full Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we will look at the feature-pairs that have more than 0.55 corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_features = set()\n",
    "# Iterate over the correlation matrix and print tuples with correlation >= 0.55\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "\tfor j in range(i+1, len(correlation_matrix.columns)):\n",
    "\t\tif abs(correlation_matrix.iloc[i, j]) > 0.55:\n",
    "\t\t\tpotential_features.add(correlation_matrix.columns[i])\n",
    "\t\t\tpotential_features.add(correlation_matrix.columns[j])\n",
    "\n",
    "for feature in battles_df_for_dag.columns:\n",
    "\tif feature not in potential_features:\n",
    "\t\tbattles_df_for_dag.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "correlation_matrix = battles_df_for_dag.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(correlation_matrix.iloc[1:,1:], annot=False, cmap='coolwarm')\n",
    "plt.title('Filtered Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define correlation matrix (example)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "# correlation_matrix = pd.DataFrame(np.random.rand(5, 5), columns=list(correlation_matrix.columns), index=list(correlation_matrix.columns))\n",
    "np.fill_diagonal(correlation_matrix.values, 1)  # Self-correlation is 1\n",
    "\n",
    "# Add edges based on correlation threshold\n",
    "correlation_threshold = 0.7\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold:\n",
    "            G.add_edge(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "\n",
    "# Use Kamada-Kawai layout\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "# Draw the DAG\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", \n",
    "        font_size=10, font_weight=\"bold\", edge_color=\"gray\")\n",
    "plt.title(\"DAG Based on Correlation Matrix (|corr| >= 0.7)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming corr_matrix is already calculated\n",
    "# Example: corr_matrix = battles_df.corr()\n",
    "\n",
    "target_col = 'win_lose_ratio'\n",
    "sorted_corr = correlation_matrix[target_col].abs().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix[sorted_corr.index[0:25]].corr(), annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(f'Correlation Matrix of Top 20 Features Most Related to {target_col}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define correlation matrix (example)\n",
    "np.random.seed(42)\n",
    "# correlation_matrix = pd.DataFrame(np.random.rand(5, 5), columns=list(correlation_matrix.columns), index=list(correlation_matrix.columns))\n",
    "np.fill_diagonal(correlation_matrix.values, 1)  # Self-correlation is 1\n",
    "\n",
    "# Add edges based on correlation threshold\n",
    "correlation_threshold = 0.25\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold:\n",
    "            G.add_edge(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "\n",
    "# Extract the subgraph containing the node 'win_lose_ratio'\n",
    "target_node = 'win_lose_ratio'\n",
    "subgraph_nodes = set(nx.single_source_shortest_path_length(G, target_node).keys())\n",
    "subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "# Use Kamada-Kawai layout\n",
    "pos = nx.kamada_kawai_layout(subgraph)\n",
    "\n",
    "# Draw the subgraph\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(subgraph, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", \n",
    "        font_size=10, font_weight=\"bold\", edge_color=\"gray\")\n",
    "plt.title(\"Subgraph Containing 'win_lose_ratio'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "battles_df_for_dag['win_lose_ratio'].head(100)\n",
    "battles_df[\"win_lose_ratio\"] = (battles_df[\"winner_count\"] / (battles_df[\"loser_count\"] + 1e-6)).round(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = battles_df_for_dag.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define correlation matrix (example)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "# correlation_matrix = pd.DataFrame(np.random.rand(5, 5), columns=list(correlation_matrix.columns), index=list(correlation_matrix.columns))\n",
    "np.fill_diagonal(correlation_matrix.values, 1)  # Self-correlation is 1\n",
    "\n",
    "# Add edges based on correlation threshold\n",
    "correlation_threshold = 0.7\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold:\n",
    "            G.add_edge(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "\n",
    "# Use Kamada-Kawai layout\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "\n",
    "# Draw the DAG\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", \n",
    "        font_size=10, font_weight=\"bold\", edge_color=\"gray\")\n",
    "plt.title(\"DAG Based on Correlation Matrix (|corr| >= 0.7)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define correlation matrix (example)\n",
    "np.random.seed(42)\n",
    "# correlation_matrix = pd.DataFrame(np.random.rand(5, 5), columns=list(correlation_matrix.columns), index=list(correlation_matrix.columns))\n",
    "np.fill_diagonal(correlation_matrix.values, 1)  # Self-correlation is 1\n",
    "\n",
    "# Add edges based on correlation threshold\n",
    "correlation_threshold = 0.25\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) >= correlation_threshold:\n",
    "            G.add_edge(correlation_matrix.columns[i], correlation_matrix.columns[j])\n",
    "\n",
    "# Extract the subgraph containing the node 'win_lose_ratio'\n",
    "target_node = 'win_lose_ratio'\n",
    "subgraph_nodes = set(nx.single_source_shortest_path_length(G, target_node).keys())\n",
    "subgraph = G.subgraph(subgraph_nodes)\n",
    "\n",
    "# Use Kamada-Kawai layout\n",
    "pos = nx.kamada_kawai_layout(subgraph)\n",
    "\n",
    "# Draw the subgraph\n",
    "plt.figure(figsize=(12, 8))\n",
    "nx.draw(subgraph, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", \n",
    "        font_size=10, font_weight=\"bold\", edge_color=\"gray\")\n",
    "plt.title(\"Subgraph Containing 'win_lose_ratio'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: SALEH: ADD GRAPH AS SAID\n",
    "### TODO: YAGEL AND RONI: imputation and outliers, and validate the subset data\n",
    "### TODO: YAGEL AND RONI: add DAG per target features\n",
    "### TODO: RONI: RUN PCA\n",
    "### TODO: YAGEL: RUN UPDATED DAG\n",
    "### TODO: YAGEL: UNDERSTAND WHAT TO DO WITH DAG\n",
    "### DATELINE: 18/02 14:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
